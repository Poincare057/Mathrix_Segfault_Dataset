{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import docopt\n",
    "import sys\n",
    "import pickle\n",
    "import os.path\n",
    "from datetime import datetime, date, time \n",
    "from dateutil.parser import parse\n",
    "from time import strftime\n",
    "import pyarrow\n",
    "import json\n",
    "import git\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.options.display.max_rows = 1000\n",
    "\n",
    "REPO = 'https://github.com/CSSEGISandData/COVID-19.git'\n",
    "TMP_FOLDER = '/tmp/corona/'\n",
    "TMP_GIT = os.path.join(TMP_FOLDER, 'COVID-19')\n",
    "DATA = os.path.join(TMP_GIT, 'csse_covid_19_data/csse_covid_19_daily_reports/')\n",
    "out = './'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "git pull from https://github.com/CSSEGISandData/COVID-19.git\n",
      "Getting sheets...\n"
     ]
    }
   ],
   "source": [
    "def clean_sheet_names(new_ranges):\n",
    "    indices = []    \n",
    "    # Remove all sheets that dont have a numeric header\n",
    "    numeric_sheets = [x for x in new_ranges if re.search(r'\\d', x)]\n",
    "    \n",
    "    return numeric_sheets\n",
    "\n",
    "def clone_repo(TMP_FOLDER, REPO):\n",
    "    print('Cloning Data Repo...')\n",
    "    git.Git(TMP_FOLDER).clone(REPO)\n",
    "\n",
    "# Create Tmp Folder\n",
    "if not os.path.isdir(TMP_FOLDER):\n",
    "    print('Creating folder...')\n",
    "    print('...', TMP_FOLDER)\n",
    "    os.mkdir(TMP_FOLDER)\n",
    "\n",
    "#Check if repo exists\n",
    "#git pull if it does\n",
    "if not os.path.isdir(TMP_GIT):\n",
    "    clone_repo(TMP_FOLDER, REPO)\n",
    "else:\n",
    "    try:\n",
    "        print('git pull from', REPO)\n",
    "        rep = git.Repo(TMP_GIT)\n",
    "        rep.remotes.origin.pull()\n",
    "    except:\n",
    "        print('Could not pull from', REPO)\n",
    "        sys.exit()\n",
    "    \n",
    "sheets = os.listdir(DATA)\n",
    "\n",
    "# Clean the result to the sheet tabs we want\n",
    "print('Getting sheets...')\n",
    "cleaned_sheets = clean_sheet_names(sheets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_last_updated(last_update):\n",
    "    '''\n",
    "    convert date and time in YYYYMMDD HMS format\n",
    "    '''\n",
    "    date = parse(str(last_update).split(' ')[0]).strftime(\"%Y-%m-%d\")\n",
    "    time = parse(str(last_update).split(' ')[1]).strftime('%H:%M:%S')\n",
    "    parsed_date = str(date) + ' ' + str(time)\n",
    "\n",
    "    return parsed_date\n",
    "\n",
    "def get_date(last_update):\n",
    "    return parse(str(last_update).split(' ')[0]).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "def get_csv_date(file):\n",
    "    return get_date(file.split('.')[0] + ' ')    \n",
    "\n",
    "def drop_duplicates(df_raw):\n",
    "    '''\n",
    "    Take the max date value for each province for a given date\n",
    "    '''\n",
    "    days_list = []\n",
    "    \n",
    "    for datetime in df_raw.date.unique():\n",
    "        tmp_df = df_raw[df_raw.date == datetime]\n",
    "        tmp_df = tmp_df.sort_values(['Last Update']).drop_duplicates('Province/State', keep='last')\n",
    "        days_list.append(tmp_df)\n",
    "\n",
    "    return days_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... importing data: 100%|██████████| 49/49 [00:01<00:00, 40.40it/s]\n"
     ]
    }
   ],
   "source": [
    "keep_cols = ['Confirmed', 'Country/Region', 'Deaths', 'Last Update', 'Province/State', 'Recovered']\n",
    "numeric_cols = ['Confirmed', 'Deaths', 'Recovered']\n",
    "\n",
    "def get_data(cleaned_sheets):\n",
    "    all_csv = []\n",
    "    # Import all CSV's\n",
    "    for file in tqdm(sorted(sheets), desc='... importing data: '):\n",
    "        if 'csv' in file:\n",
    "            # print('...', file)\n",
    "            tmp_df = pd.read_csv(os.path.join(DATA, file), index_col=None, header=0, parse_dates=['Last Update'])\n",
    "            tmp_df = tmp_df[keep_cols]\n",
    "            tmp_df[numeric_cols] = tmp_df[numeric_cols].fillna(0)\n",
    "            tmp_df[numeric_cols] = tmp_df[numeric_cols].astype(int)\n",
    "            tmp_df['Province/State'].fillna(tmp_df['Country/Region'], inplace=True) #If no region given, fill it with country\n",
    "\n",
    "            tmp_df['Last Update'] = tmp_df['Last Update'].apply(clean_last_updated)\n",
    "            tmp_df['date'] = tmp_df['Last Update'].apply(get_date)\n",
    "            tmp_df['file_date'] = get_csv_date(file)\n",
    "            all_csv.append(tmp_df)\n",
    "\n",
    "    # concatenate all csv's into one df\n",
    "    df_raw = pd.concat(all_csv, axis=0, ignore_index=True, sort=True)\n",
    "    df_raw = df_raw.sort_values(by=['Last Update'])\n",
    "\n",
    "    frames = drop_duplicates(df_raw)\n",
    "    tmp = pd.concat(frames, axis=0, ignore_index=True, sort=True)\n",
    "    \n",
    "    return tmp\n",
    "\n",
    "\n",
    "df = get_data(cleaned_sheets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have all the data we now need to clean it \n",
    "# - Fill null values\n",
    "# - remore suspected values\n",
    "# - change column names\n",
    "def clean_data(tmp_df):\n",
    "    if 'Demised' in tmp_df.columns:\n",
    "        tmp_df.rename(columns={'Demised':'Deaths'}, inplace=True)\n",
    "\n",
    "    if 'Country/Region' in tmp_df.columns:\n",
    "        tmp_df.rename(columns={'Country/Region':'country'}, inplace=True)\n",
    "    \n",
    "    if 'Province/State' in tmp_df.columns:\n",
    "        tmp_df.rename(columns={'Province/State':'province'}, inplace=True)\n",
    "        \n",
    "    if 'Last Update' in tmp_df.columns:\n",
    "        tmp_df.rename(columns={'Last Update':'datetime'}, inplace=True)\n",
    "        \n",
    "    if 'Suspected' in tmp_df.columns:\n",
    "        tmp_df = tmp_df.drop(columns='Suspected')\n",
    "\n",
    "    for col in tmp_df.columns:\n",
    "        tmp_df[col] = tmp_df[col].fillna(0)\n",
    "    \n",
    "    #Lower case all col names\n",
    "    tmp_df.columns = map(str.lower, tmp_df.columns) \n",
    "    return tmp_df\n",
    "\n",
    "df  = clean_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Mainland China\n",
       "1       Mainland China\n",
       "2       Mainland China\n",
       "3       Mainland China\n",
       "4       Mainland China\n",
       "             ...      \n",
       "2816            Norway\n",
       "2817    Mainland China\n",
       "2818     Hong Kong SAR\n",
       "2819             Spain\n",
       "2820                UK\n",
       "Name: country, Length: 2821, dtype: object"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_list = list(map(lambda x:x.lower().strip(), set(df.country.values)))\n",
    "# country_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['french guiana',\n",
       " 'georgia',\n",
       " 'brazil',\n",
       " 'qatar',\n",
       " 'sweden',\n",
       " 'faroe islands',\n",
       " 'vietnam',\n",
       " 'occupied palestinian territory',\n",
       " 'martinique',\n",
       " 'japan',\n",
       " 'netherlands',\n",
       " 'luxembourg',\n",
       " 'macao sar',\n",
       " 'dominican republic',\n",
       " 'morocco',\n",
       " 'togo',\n",
       " 'bosnia and herzegovina',\n",
       " 'slovakia',\n",
       " 'latvia',\n",
       " 'monaco',\n",
       " 'south africa',\n",
       " 'algeria',\n",
       " 'sri lanka',\n",
       " 'uk',\n",
       " 'iceland',\n",
       " 'poland',\n",
       " 'finland',\n",
       " 'jordan',\n",
       " 'cambodia',\n",
       " 'france',\n",
       " 'switzerland',\n",
       " 'ukraine',\n",
       " 'panama',\n",
       " 'hong kong',\n",
       " 'cyprus',\n",
       " 'armenia',\n",
       " 'iran',\n",
       " 'palestine',\n",
       " 'azerbaijan',\n",
       " 'spain',\n",
       " 'us',\n",
       " 'egypt',\n",
       " 'israel',\n",
       " 'iran (islamic republic of)',\n",
       " 'mainland china',\n",
       " 'oman',\n",
       " 'tunisia',\n",
       " 'costa rica',\n",
       " 'republic of korea',\n",
       " 'albania',\n",
       " 'iraq',\n",
       " 'colombia',\n",
       " 'ecuador',\n",
       " 'gibraltar',\n",
       " 'pakistan',\n",
       " 'st. martin',\n",
       " 'hungary',\n",
       " 'macau',\n",
       " 'bulgaria',\n",
       " 'canada',\n",
       " 'singapore',\n",
       " 'nepal',\n",
       " 'bhutan',\n",
       " 'lebanon',\n",
       " 'peru',\n",
       " 'mexico',\n",
       " 'bahrain',\n",
       " 'austria',\n",
       " 'saint barthelemy',\n",
       " 'czech republic',\n",
       " 'serbia',\n",
       " 'romania',\n",
       " 'republic of ireland',\n",
       " 'north ireland',\n",
       " 'malta',\n",
       " 'taipei and environs',\n",
       " 'new zealand',\n",
       " 'senegal',\n",
       " 'brunei',\n",
       " 'cameroon',\n",
       " 'estonia',\n",
       " 'argentina',\n",
       " 'russian federation',\n",
       " 'chile',\n",
       " 'united arab emirates',\n",
       " 'vatican city',\n",
       " 'maldives',\n",
       " 'san marino',\n",
       " 'portugal',\n",
       " 'norway',\n",
       " 'ireland',\n",
       " 'philippines',\n",
       " 'saint martin',\n",
       " 'taiwan',\n",
       " 'belarus',\n",
       " 'germany',\n",
       " 'mongolia',\n",
       " 'indonesia',\n",
       " 'saudi arabia',\n",
       " 'liechtenstein',\n",
       " 'denmark',\n",
       " 'kuwait',\n",
       " 'andorra',\n",
       " 'burkina faso',\n",
       " 'hong kong sar',\n",
       " 'nigeria',\n",
       " 'australia',\n",
       " 'ivory coast',\n",
       " 'afghanistan',\n",
       " 'bangladesh',\n",
       " 'belgium',\n",
       " 'italy',\n",
       " 'others',\n",
       " 'north macedonia',\n",
       " 'viet nam',\n",
       " 'slovenia',\n",
       " 'south korea',\n",
       " 'india',\n",
       " 'azerbaijan',\n",
       " 'malaysia',\n",
       " 'greece',\n",
       " 'thailand',\n",
       " 'russia',\n",
       " 'lithuania',\n",
       " 'channel islands',\n",
       " 'republic of moldova',\n",
       " 'holy see',\n",
       " 'moldova',\n",
       " 'croatia',\n",
       " 'paraguay']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import get_close_matches\n",
    "\n",
    "COUNTRY = 'Italy'\n",
    "\n",
    "def get_similar_countries(c, country_list):\n",
    "    pos_countries = get_close_matches(c, country_list)\n",
    "    \n",
    "    if len(pos_countries) > 0:\n",
    "        print(c, 'was not listed. did you mean', pos_countries[0].capitalize() + '?')\n",
    "        sys.exit()\n",
    "    else:\n",
    "        print(c, 'was not listed.')\n",
    "        sys.exit()\n",
    "        \n",
    "def check_specified_country(df):\n",
    "    if COUNTRY:\n",
    "        print('Country specified')\n",
    "        if COUNTRY.lower() == 'china':\n",
    "            print(COUNTRY, 'was not listed. did you mean Mainland China?')\n",
    "            \n",
    "        elif COUNTRY.lower() not in country_list:\n",
    "            get_similar_countries(COUNTRY, country_list)\n",
    "            \n",
    "        else:\n",
    "            print('... filtering data for', COUNTRY)\n",
    "            if len(COUNTRY) == 2:\n",
    "                df = df[df.country == COUNTRY.upper()]\n",
    "            else:\n",
    "                df = df[df.country == COUNTRY.capitalize()]\n",
    "            return df\n",
    "    else:\n",
    "        print('No specific country specified')\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COUNTRY.capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country specified\n",
      "... filtering data for Italy\n"
     ]
    }
   ],
   "source": [
    "df = check_specified_country(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting by datetime...\n"
     ]
    }
   ],
   "source": [
    "# sheets need to be sorted by date value\n",
    "print('Sorting by datetime...')\n",
    "current_date = str(datetime.date(datetime.now()))\n",
    "\n",
    "if df.date.max() == current_date:\n",
    "    df = df[df.date != df.date.max()]\n",
    "else:\n",
    "    df = df[df.date != current_date]\n",
    "\n",
    "df = df.sort_values('datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confirmed</th>\n",
       "      <th>country</th>\n",
       "      <th>deaths</th>\n",
       "      <th>datetime</th>\n",
       "      <th>province</th>\n",
       "      <th>recovered</th>\n",
       "      <th>date</th>\n",
       "      <th>file_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>2</td>\n",
       "      <td>Italy</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-31 23:59:00</td>\n",
       "      <td>Italy</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>2020-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>3</td>\n",
       "      <td>Italy</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-02-07 17:53:02</td>\n",
       "      <td>Italy</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-02-07</td>\n",
       "      <td>2020-02-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1332</th>\n",
       "      <td>20</td>\n",
       "      <td>Italy</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-02-21 23:33:06</td>\n",
       "      <td>Italy</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-02-21</td>\n",
       "      <td>2020-02-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>62</td>\n",
       "      <td>Italy</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-02-22 23:43:02</td>\n",
       "      <td>Italy</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-02-22</td>\n",
       "      <td>2020-02-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1409</th>\n",
       "      <td>155</td>\n",
       "      <td>Italy</td>\n",
       "      <td>3</td>\n",
       "      <td>2020-02-23 23:43:02</td>\n",
       "      <td>Italy</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-02-23</td>\n",
       "      <td>2020-02-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>229</td>\n",
       "      <td>Italy</td>\n",
       "      <td>7</td>\n",
       "      <td>2020-02-24 23:43:01</td>\n",
       "      <td>Italy</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>2020-02-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1490</th>\n",
       "      <td>322</td>\n",
       "      <td>Italy</td>\n",
       "      <td>10</td>\n",
       "      <td>2020-02-25 18:55:32</td>\n",
       "      <td>Italy</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-02-25</td>\n",
       "      <td>2020-02-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1557</th>\n",
       "      <td>453</td>\n",
       "      <td>Italy</td>\n",
       "      <td>12</td>\n",
       "      <td>2020-02-26 23:43:03</td>\n",
       "      <td>Italy</td>\n",
       "      <td>3</td>\n",
       "      <td>2020-02-26</td>\n",
       "      <td>2020-02-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1619</th>\n",
       "      <td>655</td>\n",
       "      <td>Italy</td>\n",
       "      <td>17</td>\n",
       "      <td>2020-02-27 23:23:02</td>\n",
       "      <td>Italy</td>\n",
       "      <td>45</td>\n",
       "      <td>2020-02-27</td>\n",
       "      <td>2020-02-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1673</th>\n",
       "      <td>888</td>\n",
       "      <td>Italy</td>\n",
       "      <td>21</td>\n",
       "      <td>2020-02-28 20:13:09</td>\n",
       "      <td>Italy</td>\n",
       "      <td>46</td>\n",
       "      <td>2020-02-28</td>\n",
       "      <td>2020-02-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1736</th>\n",
       "      <td>1128</td>\n",
       "      <td>Italy</td>\n",
       "      <td>29</td>\n",
       "      <td>2020-02-29 18:03:05</td>\n",
       "      <td>Italy</td>\n",
       "      <td>46</td>\n",
       "      <td>2020-02-29</td>\n",
       "      <td>2020-02-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1806</th>\n",
       "      <td>1694</td>\n",
       "      <td>Italy</td>\n",
       "      <td>34</td>\n",
       "      <td>2020-03-01 23:23:02</td>\n",
       "      <td>Italy</td>\n",
       "      <td>83</td>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>2020-03-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1872</th>\n",
       "      <td>2036</td>\n",
       "      <td>Italy</td>\n",
       "      <td>52</td>\n",
       "      <td>2020-03-02 20:23:16</td>\n",
       "      <td>Italy</td>\n",
       "      <td>149</td>\n",
       "      <td>2020-03-02</td>\n",
       "      <td>2020-03-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>2502</td>\n",
       "      <td>Italy</td>\n",
       "      <td>79</td>\n",
       "      <td>2020-03-03 20:03:06</td>\n",
       "      <td>Italy</td>\n",
       "      <td>160</td>\n",
       "      <td>2020-03-03</td>\n",
       "      <td>2020-03-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2050</th>\n",
       "      <td>3089</td>\n",
       "      <td>Italy</td>\n",
       "      <td>107</td>\n",
       "      <td>2020-03-04 19:23:03</td>\n",
       "      <td>Italy</td>\n",
       "      <td>276</td>\n",
       "      <td>2020-03-04</td>\n",
       "      <td>2020-03-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2141</th>\n",
       "      <td>3858</td>\n",
       "      <td>Italy</td>\n",
       "      <td>148</td>\n",
       "      <td>2020-03-05 17:43:03</td>\n",
       "      <td>Italy</td>\n",
       "      <td>414</td>\n",
       "      <td>2020-03-05</td>\n",
       "      <td>2020-03-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2262</th>\n",
       "      <td>4636</td>\n",
       "      <td>Italy</td>\n",
       "      <td>197</td>\n",
       "      <td>2020-03-06 17:33:03</td>\n",
       "      <td>Italy</td>\n",
       "      <td>523</td>\n",
       "      <td>2020-03-06</td>\n",
       "      <td>2020-03-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2367</th>\n",
       "      <td>5883</td>\n",
       "      <td>Italy</td>\n",
       "      <td>233</td>\n",
       "      <td>2020-03-07 17:33:03</td>\n",
       "      <td>Italy</td>\n",
       "      <td>589</td>\n",
       "      <td>2020-03-07</td>\n",
       "      <td>2020-03-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2508</th>\n",
       "      <td>7375</td>\n",
       "      <td>Italy</td>\n",
       "      <td>366</td>\n",
       "      <td>2020-03-08 18:03:04</td>\n",
       "      <td>Italy</td>\n",
       "      <td>622</td>\n",
       "      <td>2020-03-08</td>\n",
       "      <td>2020-03-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2640</th>\n",
       "      <td>9172</td>\n",
       "      <td>Italy</td>\n",
       "      <td>463</td>\n",
       "      <td>2020-03-09 18:13:11</td>\n",
       "      <td>Italy</td>\n",
       "      <td>724</td>\n",
       "      <td>2020-03-09</td>\n",
       "      <td>2020-03-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2786</th>\n",
       "      <td>10149</td>\n",
       "      <td>Italy</td>\n",
       "      <td>631</td>\n",
       "      <td>2020-03-10 17:53:02</td>\n",
       "      <td>Italy</td>\n",
       "      <td>724</td>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>2020-03-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      confirmed country  deaths             datetime province  recovered  \\\n",
       "447           2   Italy       0  2020-01-31 23:59:00    Italy          0   \n",
       "771           3   Italy       0  2020-02-07 17:53:02    Italy          0   \n",
       "1332         20   Italy       1  2020-02-21 23:33:06    Italy          0   \n",
       "1369         62   Italy       2  2020-02-22 23:43:02    Italy          1   \n",
       "1409        155   Italy       3  2020-02-23 23:43:02    Italy          2   \n",
       "1455        229   Italy       7  2020-02-24 23:43:01    Italy          1   \n",
       "1490        322   Italy      10  2020-02-25 18:55:32    Italy          1   \n",
       "1557        453   Italy      12  2020-02-26 23:43:03    Italy          3   \n",
       "1619        655   Italy      17  2020-02-27 23:23:02    Italy         45   \n",
       "1673        888   Italy      21  2020-02-28 20:13:09    Italy         46   \n",
       "1736       1128   Italy      29  2020-02-29 18:03:05    Italy         46   \n",
       "1806       1694   Italy      34  2020-03-01 23:23:02    Italy         83   \n",
       "1872       2036   Italy      52  2020-03-02 20:23:16    Italy        149   \n",
       "1978       2502   Italy      79  2020-03-03 20:03:06    Italy        160   \n",
       "2050       3089   Italy     107  2020-03-04 19:23:03    Italy        276   \n",
       "2141       3858   Italy     148  2020-03-05 17:43:03    Italy        414   \n",
       "2262       4636   Italy     197  2020-03-06 17:33:03    Italy        523   \n",
       "2367       5883   Italy     233  2020-03-07 17:33:03    Italy        589   \n",
       "2508       7375   Italy     366  2020-03-08 18:03:04    Italy        622   \n",
       "2640       9172   Italy     463  2020-03-09 18:13:11    Italy        724   \n",
       "2786      10149   Italy     631  2020-03-10 17:53:02    Italy        724   \n",
       "\n",
       "            date   file_date  \n",
       "447   2020-01-31  2020-01-31  \n",
       "771   2020-02-07  2020-02-11  \n",
       "1332  2020-02-21  2020-02-21  \n",
       "1369  2020-02-22  2020-02-22  \n",
       "1409  2020-02-23  2020-02-23  \n",
       "1455  2020-02-24  2020-02-24  \n",
       "1490  2020-02-25  2020-02-25  \n",
       "1557  2020-02-26  2020-02-26  \n",
       "1619  2020-02-27  2020-02-27  \n",
       "1673  2020-02-28  2020-02-28  \n",
       "1736  2020-02-29  2020-02-29  \n",
       "1806  2020-03-01  2020-03-01  \n",
       "1872  2020-03-02  2020-03-02  \n",
       "1978  2020-03-03  2020-03-03  \n",
       "2050  2020-03-04  2020-03-04  \n",
       "2141  2020-03-05  2020-03-05  \n",
       "2262  2020-03-06  2020-03-06  \n",
       "2367  2020-03-07  2020-03-07  \n",
       "2508  2020-03-08  2020-03-08  \n",
       "2640  2020-03-09  2020-03-09  \n",
       "2786  2020-03-10  2020-03-10  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Get the difference of the sum totals for each\n",
    "date and plot them on a trendline graph\n",
    "'''\n",
    "def get_new_cases(tmp, col):\n",
    "    diff_list = []\n",
    "    tmp_df_list = []\n",
    "    df = tmp.copy()\n",
    "\n",
    "    for i, day in enumerate(df.sort_values('date').date.unique()):    \n",
    "        tmp_df = df[df.date == day]\n",
    "        tmp_df_list.append(tmp_df[col].sum())\n",
    "        \n",
    "        if i == 0:\n",
    "            diff_list.append(tmp_df[col].sum())\n",
    "        else:\n",
    "            diff_list.append(tmp_df[col].sum() - tmp_df_list[i-1])\n",
    "        \n",
    "    return diff_list\n",
    "\n",
    "def get_moving_average(tmp, col):\n",
    "    df = tmp.copy()\n",
    "    return df[col].rolling(window=2).mean()\n",
    "\n",
    "def get_exp_moving_average(tmp, col):\n",
    "    df = tmp.copy()\n",
    "    return df[col].ewm(span=2, adjust=True).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating dataframe for new cases...\n"
     ]
    }
   ],
   "source": [
    "print('Calculating dataframe for new cases...')\n",
    "daily_cases_df = pd.DataFrame([])\n",
    "daily_cases_df['new_confirmed_cases'] = get_new_cases(df, 'confirmed')\n",
    "daily_cases_df['new_deaths'] = get_new_cases(df, 'deaths')\n",
    "daily_cases_df['new_recoveries'] = get_new_cases(df, 'recovered')\n",
    "daily_cases_df['date'] = df.date.unique()\n",
    "\n",
    "#Moving average\n",
    "daily_cases_df['confirmed_MA'] = get_moving_average(daily_cases_df, 'new_confirmed_cases')\n",
    "daily_cases_df['deaths_MA'] = get_moving_average(daily_cases_df, 'new_deaths')\n",
    "daily_cases_df['recovered_MA'] = get_moving_average(daily_cases_df, 'new_recoveries')\n",
    "\n",
    "#Exponential moving average\n",
    "daily_cases_df['confirmed_exp_MA'] = get_exp_moving_average(daily_cases_df, 'new_confirmed_cases')\n",
    "daily_cases_df['deaths_exp_MA'] = get_exp_moving_average(daily_cases_df, 'new_deaths')\n",
    "daily_cases_df['recovered_exp_MA'] = get_exp_moving_average(daily_cases_df, 'new_recoveries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Calculate the number of people that are ACTUALLY infected on a given day\n",
    "currently infected = sum of people date - (recovored + died)\n",
    "ex: 5 = 10 - (4 - 1)\n",
    "\n",
    "'''\n",
    "current_infected = pd.DataFrame([])\n",
    "current_infected['currently_infected'] = (df.groupby('date').confirmed.sum() - \\\n",
    "                                          (df.groupby('date').deaths.sum() + df.groupby('date').recovered.sum()))\n",
    "current_infected['delta'] = (current_infected['currently_infected'] - df.groupby('date').confirmed.sum())\n",
    "daily_cases_df = pd.merge(daily_cases_df, current_infected, how='outer', on='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating subdirectory for data...\n",
      "... ./data/2020-03-11\n",
      "Saving...\n",
      "... agg_data_2020-03-11.parquet.gzip\n",
      "... agg_data_2020-03-11.csv\n",
      "... trend_2020-03-11.csv\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#Create date of extraction folder\n",
    "data_folder = os.path.join('data', str(datetime.date(datetime.now())))\n",
    "save_dir = os.path.join(out, data_folder)\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.system('mkdir -p ' + save_dir)\n",
    "\n",
    "print('Creating subdirectory for data...')\n",
    "print('...', save_dir)\n",
    "\n",
    "print('Saving...')\n",
    "file_name = 'agg_data_{}.parquet.gzip'.format(datetime.date(datetime.now()))\n",
    "df.astype(str).to_parquet(os.path.join(save_dir, file_name), compression='gzip')\n",
    "print('...', file_name)\n",
    "\n",
    "\n",
    "csv_file_name = 'agg_data_{}.csv'.format(datetime.date(datetime.now()))\n",
    "df.astype(str).to_csv(os.path.join(save_dir, csv_file_name))\n",
    "print('...', csv_file_name)\n",
    "\n",
    "\n",
    "daily_cases_file_name = 'trend_{}.csv'.format(datetime.date(datetime.now()))\n",
    "daily_cases_df.astype(str).to_csv(os.path.join(save_dir, daily_cases_file_name))\n",
    "print('...', daily_cases_file_name)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit ('anaconda3': virtualenv)",
   "language": "python",
   "name": "python36864bitanaconda3virtualenv59e2ff4492e04649af7e0fd703909eac"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
